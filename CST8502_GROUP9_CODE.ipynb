{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CST 8502 FINAL PROJECT\n",
    "\n",
    "By:  \n",
    "Charles-Antoine Campeau  \n",
    "Joshua Ayyasamy  \n",
    "Mubarak husain Shaikh  \n",
    "Curtis Sloan \n",
    "\n",
    "Submitted to Dr. Anu Thomas in partial fulfillment of the requirements of CST 8502 \n",
    "\n",
    "Algonquin College Artificial Intelligence Software Development\n",
    "\n",
    "2023-11-26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA PREPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the CSV\n",
    "bicycleTheftData = pd.read_csv(\"bicycle-thefts - 4326.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the unnecessary attributes\n",
    "bicycleTheftData = bicycleTheftData.drop(columns=[\"_id\",\"EVENT_UNIQUE_ID\", \"OCC_DATE\", \"OCC_YEAR\", \"OCC_DAY\",\n",
    "                                                   \"OCC_DOY\", \"REPORT_DATE\", \"REPORT_YEAR\", \"REPORT_MONTH\", \"REPORT_DOW\", \"REPORT_DAY\", \n",
    "                                                     \"REPORT_DOY\", \"REPORT_HOUR\", \"LOCATION_TYPE\", \"BIKE_MODEL\", \"STATUS\", \"geometry\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA CLEANING & CONSTRUCTION\n",
    "The data cleaning and construction was separated between all members.  Everyone's contribution is indicated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Charles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the CSV with the BIKE_MAKE changes\n",
    "makesData = pd.read_csv(\"MAKESREPLACEMENT.CSV\", delimiter=\";\")\n",
    "# Set the index as the good values and convert the strings to list\n",
    "makesData.set_index(\"NEW\", inplace=True)\n",
    "makesData[\"OLD\"] = makesData[\"OLD\"].str.split(\",\")\n",
    "\n",
    "# Convert the list to a series\n",
    "makesSeries = makesData[\"OLD\"].explode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetMake(make):\n",
    "    \"\"\"Correct wrongfully inputted bicycle makes \\n\n",
    "    Parameter:\n",
    "    ------------\n",
    "    make: The instance bicycle make\n",
    "\n",
    "    Return:\n",
    "    -----------\n",
    "    The properly written make\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        index = makesSeries.index[makesSeries.str.contains(re.escape(make))][0]\n",
    "        return index\n",
    "    except: \n",
    "        return make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix the errors in the BIKE_MAKE attribute\n",
    "bicycleTheftData[\"BIKE_MAKE\"] = bicycleTheftData[\"BIKE_MAKE\"].apply(GetMake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataframe for the clustering and add the BIKE_MAKE and DIVISION - Charles\n",
    "kMeanClusteringData = pd.DataFrame()\n",
    "kMeanClusteringData[\"BIKE_MAKE\"] = bicycleTheftData[\"BIKE_MAKE\"]\n",
    "kMeanClusteringData[\"DIVISION\"] = bicycleTheftData[\"DIVISION\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joshua"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bicycleTheftData['BIKE_SPEED'] = bicycleTheftData['BIKE_SPEED'].fillna(bicycleTheftData['BIKE_SPEED'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low = bicycleTheftData['BIKE_COST'].quantile(.25)\n",
    "average = bicycleTheftData['BIKE_COST'].quantile(.5)\n",
    "high = bicycleTheftData['BIKE_COST'].quantile(.75)\n",
    "bicycleTheftData['BIKE_COST_CATEGORY'] = np.select(\n",
    "    [\n",
    "        bicycleTheftData['BIKE_COST'].isna(),\n",
    "        bicycleTheftData['BIKE_COST'] <= low,\n",
    "        (bicycleTheftData['BIKE_COST'] > low) & (bicycleTheftData['BIKE_COST'] <= average),\n",
    "        (bicycleTheftData['BIKE_COST'] > average) & (bicycleTheftData['BIKE_COST'] <= high),\n",
    "        bicycleTheftData['BIKE_COST'] > high\n",
    "    ],\n",
    "    [\n",
    "        'NK',\n",
    "        'Low',\n",
    "        'Average',\n",
    "        'High',\n",
    "        'Luxury'\n",
    "    ],\n",
    "    default='Unknown'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bicycleTheftData = bicycleTheftData.drop(['BIKE_COST'], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Binning of BIKE_SPEED\n",
    "low = bicycleTheftData['BIKE_SPEED'].quantile(.25)\n",
    "average = bicycleTheftData['BIKE_SPEED'].quantile(.5)\n",
    "high = bicycleTheftData['BIKE_SPEED'].quantile(.75)\n",
    "bicycleTheftData['BIKE_SPEED_CATEGORY'] = np.select(\n",
    "    [\n",
    "        bicycleTheftData['BIKE_SPEED'].isna(),\n",
    "        bicycleTheftData['BIKE_SPEED'] <= low,\n",
    "        (bicycleTheftData['BIKE_SPEED'] > low) & (bicycleTheftData['BIKE_SPEED'] <= average),\n",
    "        (bicycleTheftData['BIKE_SPEED'] > average) & (bicycleTheftData['BIKE_SPEED'] <= high),\n",
    "        bicycleTheftData['BIKE_SPEED'] > high\n",
    "    ],\n",
    "    [\n",
    "        'NK',\n",
    "        'Slow-Speeding',\n",
    "        'Average-Speeding',\n",
    "        'Fast-Speeding',\n",
    "        'Racing'\n",
    "    ],\n",
    "    default='Unknown'\n",
    ")\n",
    "bicycleTheftData = bicycleTheftData.drop(['BIKE_SPEED'], axis =1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the BIKE_COST_CATEGORY and the BIKE_SPEED_CATEGORY to the clustering dataframe - Charles\n",
    "kMeanClusteringData[\"BIKE_COST_CATEGORY\"] = bicycleTheftData[\"BIKE_COST_CATEGORY\"]\n",
    "kMeanClusteringData[\"BIKE_SPEED_CATEGORY\"] = bicycleTheftData[\"BIKE_SPEED_CATEGORY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mubarak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace missing values in PRIMARY_OFFENCE with 'Unknown'\n",
    "bicycleTheftData['PRIMARY_OFFENCE'].fillna('Unknown', inplace=True)\n",
    "\n",
    "# Convert entries to lowercase for uniformity\n",
    "bicycleTheftData['PRIMARY_OFFENCE'] = bicycleTheftData['PRIMARY_OFFENCE'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#there is one instance colored as '18' so to handle such anomalies we will replace it with unknown\n",
    "bicycleTheftData['BIKE_COLOUR'] = bicycleTheftData['BIKE_COLOUR'].replace('18', 'Unknown')\n",
    "\n",
    "bicycleTheftData['BIKE_COLOUR'].fillna('Unknown', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to categorize colors\n",
    "def categorize_color(color):\n",
    "    color = color.lower()  # Convert to lowercase for uniformity\n",
    "\n",
    "    color_categories = {\n",
    "        'black': ['black', 'blk', 'blac'],\n",
    "        'blue': ['blue', 'blu'],\n",
    "        'brown': ['brown', 'brn'],\n",
    "        'beige': ['bge', 'beige'],\n",
    "        'gold': ['gold', 'gld'],\n",
    "        'green': ['green', 'grn'],\n",
    "        'grey': ['grey', 'gray', 'gry'],\n",
    "        'orange': ['orange', 'ong'],\n",
    "        'pink': ['pink', 'pnk'],\n",
    "        'purple': ['purple', 'purp'],\n",
    "        'red': ['red', 'rd'],\n",
    "        'silver': ['silver', 'sil'],\n",
    "        'turquoise': ['turquoise', 'trq'],\n",
    "        'white': ['white', 'whi'],\n",
    "        'yellow': ['yellow', 'yel']\n",
    "       \n",
    "    }\n",
    "\n",
    "    for category, values in color_categories.items():\n",
    "        for value in values:\n",
    "            if value in color:\n",
    "                return category\n",
    "\n",
    "    return 'Unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the categorize_color function to the BIKE_COLOUR column\n",
    "bicycleTheftData['BIKE_COLOUR'] = bicycleTheftData['BIKE_COLOUR'].apply(categorize_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the PRIMARY_OFFENCE and BIKE_COLOUR to the clustering dataframe - Charles\n",
    "kMeanClusteringData[\"PRIMARY_OFFENCE\"] = bicycleTheftData[\"PRIMARY_OFFENCE\"]\n",
    "kMeanClusteringData[\"BIKE_COLOUR\"] = bicycleTheftData[\"BIKE_COLOUR\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Curtis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def month_to_number(data):\n",
    "    months = [\"January\", \"February\", \"March\",\"April\", \"May\", \"June\",\n",
    "              \"July\", \"August\", \"September\",\"October\", \"November\", \"December\"]\n",
    "    \n",
    "    if data in months:\n",
    "        return months.index(data) + 1\n",
    "\n",
    "bicycleTheftData['OCC_MONTH'] = bicycleTheftData['OCC_MONTH'].apply(month_to_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def day_to_number(data):\n",
    "    days = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\",\n",
    "            \"Friday\", \"Saturday\", \"Sunday\"]\n",
    "    \n",
    "    if data in days:\n",
    "        return days.index(data) + 1\n",
    "\n",
    "bicycleTheftData[\"OCC_DOW\"] = bicycleTheftData[\"OCC_DOW\"].apply(day_to_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the OCC_MONTH, OCC_DOW, PREMISES_TYPE, and BIKE_TYPE to the clustering dataframe - Charles\n",
    "kMeanClusteringData[\"OCC_MONTH\"] = bicycleTheftData[\"OCC_MONTH\"]\n",
    "kMeanClusteringData[\"OCC_DOW\"] = bicycleTheftData[\"OCC_DOW\"]\n",
    "kMeanClusteringData[\"PREMISES_TYPE\"] = bicycleTheftData[\"PREMISES_TYPE\"]\n",
    "kMeanClusteringData[\"BIKE_TYPE\"] = bicycleTheftData[\"BIKE_TYPE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder()\n",
    "\n",
    "encoded = pd.DataFrame(ohe.fit_transform(bicycleTheftData[['PREMISES_TYPE']]).toarray())\n",
    "encoded.columns = ['Apartment','House','Commercial','Outside','Transit','Educational','Other']\n",
    "bicycleTheftData = bicycleTheftData.join(encoded)\n",
    "\n",
    "\n",
    "encoded = pd.DataFrame(ohe.fit_transform(bicycleTheftData[['BIKE_TYPE']]).toarray())\n",
    "encoded.columns = ['BM','EL','FO','MT','OT','RC','RE','RG','SC','TA','TO','TR','UN']\n",
    "bicycleTheftData = bicycleTheftData.join(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bicycleTheftData = bicycleTheftData.drop(['PREMISES_TYPE'], axis=1)\n",
    "bicycleTheftData = bicycleTheftData.drop(['BIKE_TYPE'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_of_day(data):\n",
    "    if pd.isnull(data):\n",
    "        return \"Unknown\"\n",
    "    elif data <= 4:\n",
    "        return \"Night\"\n",
    "    elif data <= 8:\n",
    "        return \"Dawn\"\n",
    "    elif data <= 11:\n",
    "        return \"Morning\"\n",
    "    elif data <= 16:\n",
    "        return \"Afternoon\"\n",
    "    elif data <= 21:\n",
    "        return \"Evening\"\n",
    "    else:\n",
    "        return \"Night\"\n",
    "    \n",
    "bicycleTheftData[\"OCC_TOD\"] = bicycleTheftData[\"OCC_HOUR\"].apply(time_of_day)\n",
    "bicycleTheftData = bicycleTheftData.drop(['OCC_HOUR'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the OCC_TOD to the clustering dataframe - Charles\n",
    "kMeanClusteringData[\"OCC_TOD\"] = bicycleTheftData[\"OCC_TOD\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the nominal attributes into category\n",
    "kMeanClusteringData[\"BIKE_MAKE\"] = kMeanClusteringData[\"BIKE_MAKE\"].astype(\"category\")\n",
    "kMeanClusteringData[\"DIVISION\"] = kMeanClusteringData[\"DIVISION\"].astype(\"category\")\n",
    "kMeanClusteringData[\"BIKE_COST_CATEGORY\"] = kMeanClusteringData[\"BIKE_COST_CATEGORY\"].astype(\"category\")\n",
    "kMeanClusteringData[\"BIKE_SPEED_CATEGORY\"] = kMeanClusteringData[\"BIKE_SPEED_CATEGORY\"].astype(\"category\")\n",
    "kMeanClusteringData[\"PRIMARY_OFFENCE\"] = kMeanClusteringData[\"PRIMARY_OFFENCE\"].astype(\"category\")\n",
    "kMeanClusteringData[\"BIKE_COLOUR\"] = kMeanClusteringData[\"BIKE_COLOUR\"].astype(\"category\")\n",
    "kMeanClusteringData[\"PREMISES_TYPE\"] = kMeanClusteringData[\"PREMISES_TYPE\"].astype(\"category\")\n",
    "kMeanClusteringData[\"BIKE_TYPE\"] = kMeanClusteringData[\"BIKE_TYPE\"].astype(\"category\")\n",
    "kMeanClusteringData[\"OCC_TOD\"] = kMeanClusteringData[\"OCC_TOD\"].astype(\"category\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the category attributes into numeric\n",
    "cat_columns = kMeanClusteringData.select_dtypes([\"category\"]).columns\n",
    "kMeanClusteringData[cat_columns] = kMeanClusteringData[cat_columns].apply(lambda x: x.cat.codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into a train and test subset\n",
    "clusteringTrain, clusteringTest = train_test_split(kMeanClusteringData, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determining K\n",
    "To determine the proper value of K, multiple models are created with different K values to determine the distortion and inertia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list to keep the values of distortion and inertia for different K\n",
    "distortions = []\n",
    "inertias = []\n",
    "K = range(1, 10)\n",
    "\n",
    "for k in K:\n",
    "    # Build the model\n",
    "    kmeanModel = KMeans(n_clusters=k, n_init='auto').fit(clusteringTrain)\n",
    "    kmeanModel.fit(clusteringTrain)\n",
    "    \n",
    "    # Append the values\n",
    "    distortions.append(sum(np.min(cdist(clusteringTrain, kmeanModel.cluster_centers_, 'euclidean'), axis=1)) / clusteringTrain.shape[0])\n",
    "    inertias.append(kmeanModel.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distortion\n",
    "plt.plot(K, distortions, 'bx-')\n",
    "plt.xlabel('Values of K')\n",
    "plt.ylabel('Distortion')\n",
    "plt.title('The Elbow Method using Distortion')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the inertia\n",
    "plt.plot(K, inertias, 'bx-')\n",
    "plt.xlabel('Values of K')\n",
    "plt.ylabel('Inertia')\n",
    "plt.title('The Elbow Method using Inertia')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting K-Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce the number of columns to be able to plot in a 2D graph\n",
    "pca = PCA(2)\n",
    "reducedClusteringTrainData = pca.fit_transform(clusteringTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the KMeans algorithm and cluster the training data\n",
    "kmeans = KMeans(n_clusters= 4, n_init=\"auto\")\n",
    "trainLablels = kmeans.fit_predict(reducedClusteringTrainData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting unique labels\n",
    "u_labels = np.unique(trainLablels)\n",
    " \n",
    "#plotting the results:\n",
    "for i in u_labels:\n",
    "    plt.scatter(reducedClusteringTrainData[trainLablels == i , 0] , reducedClusteringTrainData[trainLablels == i , 1] , label= i)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the Centroids\n",
    "centroids = kmeans.cluster_centers_\n",
    "u_labels = np.unique(trainLablels)\n",
    " \n",
    "#plotting the results:\n",
    "for i in u_labels:\n",
    "    plt.scatter(reducedClusteringTrainData[trainLablels == i , 0] , reducedClusteringTrainData[trainLablels == i , 1] , label= i)\n",
    "plt.scatter(centroids[:,0] , centroids[:,1] , s = 80, color = 'k')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare to Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce the number of columns to be able to plot in a 2D graph\n",
    "reducedClusteringTestData = pca.fit_transform(clusteringTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the KMeans algorithm and cluster the training data\n",
    "kmeans = KMeans(n_clusters= 4, n_init=\"auto\")\n",
    "testLabels = kmeans.fit_predict(reducedClusteringTestData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting unique labels\n",
    "u_labels = np.unique(testLabels)\n",
    " \n",
    "#plotting the results:\n",
    "for i in u_labels:\n",
    "    plt.scatter(reducedClusteringTestData[testLabels == i , 0] , reducedClusteringTestData[testLabels == i , 1] , label = i)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the Centroids\n",
    "centroids = kmeans.cluster_centers_\n",
    "u_labels = np.unique(testLabels)\n",
    " \n",
    "#plotting the results:\n",
    "for i in u_labels:\n",
    "    plt.scatter(reducedClusteringTestData[testLabels == i , 0] , reducedClusteringTestData[testLabels == i , 1] , label = i)\n",
    "plt.scatter(centroids[:,0] , centroids[:,1] , s = 80, color = 'k')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the cluster number to each instance\n",
    "clusteringTrain[\"CLUSTER\"] = trainLablels\n",
    "\n",
    "# save the description of each cluster to csv\n",
    "for x in range(0,4):\n",
    "    clusteringTrain.loc[clusteringTrain[\"CLUSTER\"] == x].describe().to_csv(\"TRAINCLUSTER{0}.csv\".format(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the cluster number to each instance\n",
    "clusteringTest[\"CLUSTER\"] = testLabels\n",
    "\n",
    "# save the description of each cluster to csv\n",
    "for x in range(0,4):\n",
    "    print(clusteringTest.loc[clusteringTest[\"CLUSTER\"] == x].describe())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
